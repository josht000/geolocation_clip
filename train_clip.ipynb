{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from PIL import Image \n",
    "from typing import Tuple, Any\n",
    "from datasets import DatasetDict\n",
    "from transformers import CLIPProcessor\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_dict = {\n",
    "    0: 'Tropical, rainforest',\n",
    "    1: 'Tropical, monsoon',\n",
    "    2: 'Tropical, savannah',\n",
    "    3: 'Arid, desert, hot',\n",
    "    4: 'Arid, desert, cold',\n",
    "    5: 'Arid, steppe, hot',\n",
    "    6: 'Arid, steppe, cold',\n",
    "    7: 'Temperate, dry summer, hot summer',\n",
    "    8: 'Temperate, dry summer, warm summer',\n",
    "    9: 'Temperate, dry summer, cold summer',\n",
    "    10: 'Temperate, dry winter, hot summer',\n",
    "    11: 'Temperate, dry winter, warm summer',\n",
    "    12: 'Temperate, dry winter, cold summer',\n",
    "    13: 'Temperate, no dry season, hot summer',\n",
    "    14: 'Temperate, no dry season, warm summer',\n",
    "    15: 'Temperate, no dry season, cold summer',\n",
    "    16: 'Cold, dry summer, hot summer',\n",
    "    17: 'Cold, dry summer, warm summer',\n",
    "    18: 'Cold, dry summer, cold summer',\n",
    "    19: 'Cold, dry summer, very cold winter',\n",
    "    20: 'Cold, dry winter, hot summer',\n",
    "    21: 'Cold, dry winter, warm summer',\n",
    "    22: 'Cold, dry winter, cold summer',\n",
    "    23: 'Cold, dry winter, very cold winter',\n",
    "    24: 'Cold, no dry season, hot summer',\n",
    "    25: 'Cold, no dry season, warm summer',\n",
    "    26: 'Cold, no dry season, cold summer',\n",
    "    27: 'Cold, no dry season, very cold winter',\n",
    "    28: 'Polar, tundra',\n",
    "    29: 'Polar, frost'\n",
    "}\n",
    "\n",
    "class PretrainDatasetOSVMini(torch.utils.data.Dataset):\n",
    "    \"Pretrain CLIP on osv-mini-129k\"\n",
    "    def __init__(self, split: str, dir: str, shuffle: bool=True, image_size: int=224):\n",
    "        \"\"\"Initializes a PretrainDatasetYFCC used for pretraining CLIP.\n",
    "\n",
    "        Args:\n",
    "            split (str): dataset split to load.\n",
    "            dir (str): path to parent directory of the dataset. Must include train_mini.csv, \n",
    "                        val_mini.csv, test_images, and train_images directories.\n",
    "            shuffle (bool, optional): whether the training data should be shuffled. \n",
    "                                        Defaults to True.\n",
    "            image_size (int, optional): the size to which the image should be resized. \n",
    "                                        Base uses 224, Large uses 336.\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.shuffle = shuffle\n",
    "        self.image_size = image_size\n",
    "        self.dir = dir\n",
    "        self.image_dir = os.path.join(dir, f'{split}_images')\n",
    "        self.csv_path = os.path.join(dir, f'{split}_mini.csv')\n",
    "\n",
    "        # basic checks\n",
    "        assert split in ['train', 'val', 'test']\n",
    "        assert os.path.exists(dir)\n",
    "        assert os.path.exists(self.csv_path), f\"CSV file does not exist: {self.csv_path}\"\n",
    "        assert os.path.exists(self.image_dir), f\"Image directory does not exist: {self.image_dir}\"\n",
    "        \n",
    "        # load data\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        self.df.drop(columns=[\"creator_username\", \"creator_id\", 'thumb_original_url', 'sequence', \"road_index\", 'drive_side', 'soil'], inplace=True)\n",
    "        self.df = self.df.rename(columns={'region': 'state'})\n",
    "        print(f'Any NaNs: {self.df.isna().any().any()}')\n",
    "\n",
    "        if shuffle:\n",
    "            self.df = self.df.sample(frac=1.0, random_state=330)\n",
    "\n",
    "        shuffle_str = 'shuffled ' if shuffle else ''\n",
    "        print(f'Initialized {shuffle_str}{split} OSV-Mini-129k dataset with {len(self.df)} samples in metadata.')\n",
    "        \n",
    "    def _get_month(self, captured_at: int) -> str:\n",
    "        \"Gets month from capture_at column\"\n",
    "        # Convert to datetime object and save month as int\n",
    "        datetime_obj = datetime.datetime.fromtimestamp(captured_at/1000)\n",
    "        month = int(datetime_obj.strftime(\"%m\"))\n",
    "        dates = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "        return dates[month]\n",
    "    \n",
    "    def _get_climate(self, climate_int: int) -> str:\n",
    "        return climate_dict[climate_int]\n",
    "    \n",
    "    def _select_caption(self, index: int) -> str:\n",
    "        \"\"\"Generates a random caption for the given image using auxiliary data.\n",
    "\n",
    "        EXAMPLE CAPTION:\n",
    "            Location: A photo in the {CITY} city, {COUNTY} county, {STATE} state.\n",
    "            Climate: This location has a temperate oceanic climate.\n",
    "            Month: This photo was taken in December.\n",
    "\n",
    "        Args:\n",
    "            index (int): row index to generate caption for.\n",
    "\n",
    "        Returns:\n",
    "            str: randomly generated caption.\n",
    "        \"\"\"\n",
    "        s = self.df.iloc[index]\n",
    "        state = s.state\n",
    "        city = s.city\n",
    "        county = s['sub-region']\n",
    "        print(f'captured_at: {s.captured_at}, type: {type(s.captured_at)}')\n",
    "        month = self._get_month(s.captured_at)\n",
    "        climate = self._get_climate(int(s.climate))\n",
    "\n",
    "        location_str = f\"A photo in {city} city, {county}, in the state of {state}.\"\n",
    "        climate_str = f\"This location has a {climate} climate.\"\n",
    "        month_str = f\"This photo was taken in {month}.\"\n",
    "        return location_str + ' ' + climate_str + ' ' + month_str\n",
    "    \n",
    "    def _crop_resize(self, image: Image.Image) -> Image.Image:\n",
    "        \"\"\"Crops and resizes the given image.\n",
    "        \n",
    "        Args:\n",
    "            image (Image.Image): The image to be cropped and resized.\n",
    "            \n",
    "        Returns:\n",
    "            Image.Image: The cropped and resized image.\n",
    "        \"\"\"\n",
    "        # Crop the image to the largest possible square\n",
    "        width, height = image.size\n",
    "        new_dim = min(width, height)\n",
    "        left = (width - new_dim) / 2\n",
    "        top = (height - new_dim) / 2\n",
    "        right = (width + new_dim) / 2\n",
    "        bottom = (height + new_dim) / 2\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "\n",
    "        # Resize the cropped image to a side length of self.image_size pixels\n",
    "        return image.resize((self.image_size, self.image_size))\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple:\n",
    "        \"\"\"Retrieves item in dataset for given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): sample index.\n",
    "\n",
    "        Returns:\n",
    "            Dict: sample model input\n",
    "        \"\"\"\n",
    "\n",
    "        # Load the image\n",
    "        id = self.df.iloc[index]['id']\n",
    "        state = self.df.iloc[index]['state']\n",
    "        image_filename = os.path.join(self.image_dir, state, str(id) + '.jpg')\n",
    "        image = Image.open(image_filename)\n",
    "\n",
    "        # Crop image\n",
    "        image = self._crop_resize(image)\n",
    "\n",
    "        # Generate a random caption for the image\n",
    "        caption = self._select_caption(index)\n",
    "        return image, caption\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "ds = PretrainDatasetOSVMini('train', 'datasets/osv-mini-129k')\n",
    "img, caption = ds[0]\n",
    "print(f'caption: {caption}')\n",
    "img.show()\n",
    "print(f'image size: {img.size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds)):\n",
    "    img, caption = ds[i]\n",
    "    print(f'caption: {caption}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PretrainDatasetOSVMini('test', 'datasets/osv-mini-129k')\n",
    "img, caption = ds[0]\n",
    "print(f'caption: {caption}')\n",
    "img.show()\n",
    "print(f'image size: {img.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds)):\n",
    "    img, caption = ds[i]\n",
    "    print(f'caption: {caption}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pigeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
